{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df05f16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:21:37.077398Z",
     "iopub.status.busy": "2025-11-24T07:21:37.077156Z",
     "iopub.status.idle": "2025-11-24T07:21:38.345884Z",
     "shell.execute_reply": "2025-11-24T07:21:38.344529Z"
    },
    "papermill": {
     "duration": 1.274497,
     "end_time": "2025-11-24T07:21:38.347795",
     "exception": false,
     "start_time": "2025-11-24T07:21:37.073298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EV+Onehot Model Training Pipeline\n",
    "# This notebook demonstrates training workflows for protein fitness prediction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import sys\n",
    "sys.path.insert(0, '/home/xux/Desktop/ProteinMCP/ProteinMCP/mcp-servers/ev_onehot_mcp/repo/ev_onehot')\n",
    "from predictor import JointPredictor, EVPredictor, OnehotRidgePredictor\n",
    "from util import is_valid_seq, spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8035fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:21:38.356901Z",
     "iopub.status.busy": "2025-11-24T07:21:38.356608Z",
     "iopub.status.idle": "2025-11-24T07:21:38.360984Z",
     "shell.execute_reply": "2025-11-24T07:21:38.359896Z"
    },
    "papermill": {
     "duration": 0.01115,
     "end_time": "2025-11-24T07:21:38.362871",
     "exception": false,
     "start_time": "2025-11-24T07:21:38.351721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_predictor(data_dir, train, save_path, predictor_name='ev+onehot', reg_coef='CV'):\n",
    "    predictor_cls = [EVPredictor, OnehotRidgePredictor]\n",
    "    predictor = JointPredictor(data_dir, predictor_cls, predictor_name, reg_coef=reg_coef)\n",
    "\n",
    "    predictor.train(train.seq.values, train.log_fitness.values)\n",
    "    predictor.save_model()\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326ad25e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:21:38.370980Z",
     "iopub.status.busy": "2025-11-24T07:21:38.370810Z",
     "iopub.status.idle": "2025-11-24T07:21:38.375422Z",
     "shell.execute_reply": "2025-11-24T07:21:38.374389Z"
    },
    "papermill": {
     "duration": 0.011387,
     "end_time": "2025-11-24T07:21:38.377487",
     "exception": false,
     "start_time": "2025-11-24T07:21:38.366100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_eval(data_df, train, test, data_dir):\n",
    "    reg_coef = 'CV' if len(data_df) >= 5 else 1.0\n",
    "    \n",
    "    # logger.info(f'Number of training samples: {len(train)}, testing samples: {len(test)}')\n",
    "    save_path = os.path.join(data_dir, 'ridge_model.joblib')\n",
    "    predictor = train_predictor(data_dir, train, save_path, reg_coef=reg_coef)\n",
    "\n",
    "    test['pred_fitness'] = predictor.predict(test.seq.values)\n",
    "    correlation = spearman(test['pred_fitness'].to_numpy(), test['log_fitness'].to_numpy())\n",
    "    print(f'Spearman correlation on test set: {correlation:.3f}')\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c2d892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:21:38.385708Z",
     "iopub.status.busy": "2025-11-24T07:21:38.385538Z",
     "iopub.status.idle": "2025-11-24T07:21:38.392590Z",
     "shell.execute_reply": "2025-11-24T07:21:38.391343Z"
    },
    "papermill": {
     "duration": 0.013961,
     "end_time": "2025-11-24T07:21:38.394769",
     "exception": false,
     "start_time": "2025-11-24T07:21:38.380808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    logger.info(f'Data path {args.data_dir} -----')\n",
    "    train_data_path = args.train_data_path if args.train_data_path is not None else f'{args.data_dir}/data.csv'\n",
    "\n",
    "    # Load dataset\n",
    "    data_df = pd.read_csv(train_data_path)\n",
    "    if not args.ignore_gaps:  # Necessary to run EVPredictor\n",
    "        # logger.info(\"Is checking invalid!\")\n",
    "        is_valid = data_df['seq'].apply(is_valid_seq)\n",
    "        data_df = data_df[is_valid]\n",
    "\n",
    "\n",
    "    if args.cross_val:\n",
    "        # 5-fold cross validation\n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=args.seed)\n",
    "        correlations = []\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(data_df)):\n",
    "            logger.info(f'Cross validation fold {fold+1}')\n",
    "            train = data_df.iloc[train_index]\n",
    "            test = data_df.iloc[test_index].copy()\n",
    "            corr = train_test_eval(data_df, train, test, args.data_dir)\n",
    "            correlations.append(corr)\n",
    "        avg_corr = np.mean(correlations)\n",
    "        std_corr = np.std(correlations)\n",
    "        print(f'Average Spearman correlation over 5 folds: {avg_corr:.3f} Â± {std_corr:.3f}')\n",
    "\n",
    "    elif args.test_data_path is not None:\n",
    "        train = data_df\n",
    "        test = pd.read_csv(args.test_data_path)\n",
    "        train_test_eval(data_df, train, test, args.data_dir)\n",
    "        \n",
    "    else:\n",
    "        # conventional train-test split with the specified ratio\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        logger.info(f'Performing train-test split with seed {args.seed}')\n",
    "        train, test = train_test_split(data_df, test_size=args.test_size, random_state=args.seed)\n",
    "        train_test_eval(data_df, train, test, args.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09027a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:21:38.405153Z",
     "iopub.status.busy": "2025-11-24T07:21:38.404975Z",
     "iopub.status.idle": "2025-11-24T07:21:38.410299Z",
     "shell.execute_reply": "2025-11-24T07:21:38.409180Z"
    },
    "papermill": {
     "duration": 0.013994,
     "end_time": "2025-11-24T07:21:38.412157",
     "exception": false,
     "start_time": "2025-11-24T07:21:38.398163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train ev+onehot model:'\n",
    "                                                 'python ev_onehot_train.py <dataset_name>')\n",
    "    parser.add_argument('data_dir', type=str,\n",
    "                        help='Dataset path, including following files: \\n'\n",
    "                             'data.csv,     with  `seq` and `log_fitness` columns; \\n'\n",
    "                             'wt.fasta,     containing wild-type sequences;\\n'\n",
    "                             'plmc/,        folder contain EVmutation model parameters.\\n')\n",
    "    parser.add_argument('--train_data_path', type=str, default=None, help='specify the train data csv file, default is data.csv')\n",
    "    parser.add_argument('--test_data_path', type=str, default=None, help='specify the test data csv file, default is the train data')\n",
    "    parser.add_argument('--ignore_gaps', dest='ignore_gaps', action='store_true')\n",
    "    parser.add_argument('-cv', '--cross_val', dest='cross_val', action='store_true', help='Whether to perform 5-fold cross validation, default False')\n",
    "    parser.add_argument('-s', '--seed', type=int, default=6, help='Seed for random split')\n",
    "    parser.add_argument('--test_size', type=float, default=0.2, help='Train-test split ratio, default 0.2 for testing')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4197982e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:21:38.420872Z",
     "iopub.status.busy": "2025-11-24T07:21:38.420699Z",
     "iopub.status.idle": "2025-11-24T07:21:38.425942Z",
     "shell.execute_reply": "2025-11-24T07:21:38.424749Z"
    },
    "papermill": {
     "duration": 0.011941,
     "end_time": "2025-11-24T07:21:38.427612",
     "exception": false,
     "start_time": "2025-11-24T07:21:38.415671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pipeline Demonstration\n",
      "============================================================\n",
      "\n",
      "This notebook defines training functions:\n",
      "1. train_predictor() - Creates and trains Joint EV+Onehot predictor\n",
      "2. train_test_eval() - Evaluates predictor on test set\n",
      "3. main() - Complete training pipeline with CV or train-test split\n",
      "\n",
      "For actual usage, provide:\n",
      "  - data.csv with 'seq' and 'log_fitness' columns\n",
      "  - wt.fasta with wild-type sequence\n",
      "  - plmc/ directory with EVmutation parameters\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Demonstration: Training workflow with synthetic data\n",
    "print(\"Training Pipeline Demonstration\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThis notebook defines training functions:\")\n",
    "print(\"1. train_predictor() - Creates and trains Joint EV+Onehot predictor\")\n",
    "print(\"2. train_test_eval() - Evaluates predictor on test set\")\n",
    "print(\"3. main() - Complete training pipeline with CV or train-test split\")\n",
    "print(\"\\nFor actual usage, provide:\")\n",
    "print(\"  - data.csv with 'seq' and 'log_fitness' columns\")\n",
    "print(\"  - wt.fasta with wild-type sequence\")\n",
    "print(\"  - plmc/ directory with EVmutation parameters\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.615636,
   "end_time": "2025-11-24T07:21:38.850160",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/train/train_execution.ipynb",
   "output_path": "notebooks/train/train_execution_v1.ipynb",
   "parameters": {},
   "start_time": "2025-11-24T07:21:36.234524",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}